---
title: "SentimentAnalysis"
output: html_document
---

```{r}

library(tuber)
library(syuzhet)
library(tm)
library(wordcloud)
library(sentimentr)

```

```{r}

myclientid <- "787915707001-pb0s411cau3qu5s3vqcjptgv2d6h6597.apps.googleusercontent.com"
clientsecret <- "xmruZ6naKonPGsy8am8wElPI"

yt_oauth(myclientid,clientsecret,token="")

mycomments <- get_all_comments("lVKMsaWju8w")


```
```{r}

View(mycomments$textDisplay)

```
```{r}

data <- mycomments$textDisplay

#Editing Data
y <- gsub("\n","",data)
y <- gsub("  ","",y)
View(y)

```
```{r}

#Sentiment Analysis
s  <- get_nrc_sentiment(y)
View(s)

```
```{r}

#Negative and positive words we are looking for
sentiment(y)

```
```{r}

sentiment_by(y)

```
```{r}

#See which word is positive or negative in which index
extract_sentiment_terms(y)

```
```{r}

#Sentiment analysis of all sentences
sanalysis <- cbind(y, s)
View(sanalysis)

```
```{r}

#Barplot with rainbow for sentiment analysis
barplot(colSums(s) , col = rainbow(10))

```
```{r}

#Vectorization
document <- Corpus(VectorSource(y))
inspect(document)

```
```{r}

#Editing punctuation marks
toSpace <- content_transformer(function(x,pattern) gsub(pattern, "",x))
tm_map(document,toSpace,".")
tm_map(document,toSpace,")")
tm_map(document,toSpace,":")
tm_map(document,toSpace,"/")
tm_map(document,toSpace,"+")
tm_map(document,toSpace,"!")
tm_map(document,toSpace,"^")
tm_map(document,toSpace,";")
tm_map(document,toSpace,">")
tm_map(document,toSpace,"-")
tm_map(document,toSpace,"&")
tm_map(document,removeNumbers)


```
```{r}

#Blocking repetitive words
document <- tm_map(document,removePunctuation)
inspect(document)


```
```{r}

#Word frequency , First we make it into a matrix
dtm <- TermDocumentMatrix(document)
m <- as.matrix(dtm)
aa <- sort(rowSums(m),decreasing = TRUE)
d <- data.frame(word=names(aa),freq=aa)
View(d)


```
```{r}

#Word cloud creation by word frequency
wordcloud(words = d$word , freq = d$freq , min.freq = 1 , max.words = 200 , random.order = FALSE , colors = brewer.pal(8,"Dark2"))


```
```{r}

#Words repeated 30 times or more
findFreqTerms(dtm, lowfreq = 30)

```
```{r}


#The ratio of the word 'you' to other words
findAssocs(dtm, terms = "you" , corlimit = 0.2)

```
```{r}

#By word frequency, Barplot
barplot(d[1:10,] $freq , names.arg = d[1:10,] $word)

```





